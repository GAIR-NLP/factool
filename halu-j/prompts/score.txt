I'm designing verifiers to judge whether a specific claim is correct based on evidence. There are three possible situations: Neutral / True / False. I am evaluating the quality of the verifier's responses. Your task is to score the response provided. The score range is 1-100. The ideal standard for responses are as follows:

The response should clearly point out whether the content of each piece of evidence is relevant to the claim.
The response should clearly identify the span in the claim that is particularly relevant to the relevant context in the evidence.
The response should clearly compare the related information in the claim and the evidence and provide a reasonable explanation. The explanation should be clear and reasonable.
The response should maintain faithfulness. It should not assert that the claim supports something not present in the original claim, nor should it suggest that the evidence supports something not found in the original evidence.
The response should ensure completeness, that is, all parts of the evidence that are highly relevant to the claim should be analyzed, and nothing should be omission.
The response should have a clear and reasonable logical reasoning process.

Here is the prompt for the verifier, which contains the claim and the evidence: 
{prompt}

Here is the response generated by the verifier: 
{response}

Try to be objective and start your response directly(low score for poor responses is encouraged)

You should only respond in format as described below. DO NOT RETURN ANYTHING ELSE. START YOUR RESPONSE WITH '{{'.
{{
    "reasoning": "a brief explanation of your score",
    "score": the score you provide
}}